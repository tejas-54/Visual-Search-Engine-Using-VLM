# Visual-Search-Engine-Using-VLM
This project implements a visual search engine leveraging state-of-the-art vision-language models (VLMs) to retrieve relevant images based on textual queries or sample images. The system embeds both text and images into a shared representation space, allowing for semantic search across modalities.


## Features:  
__Multi-Modal Search:__ Query using either text descriptions or example images  
__Semantic Understanding:__ Find images based on conceptual meaning, not just keywords  
__Efficient Retrieval:__ Fast similarity search using approximate nearest neighbors  
__Intuitive Web Interface:__ Simple UI for uploading images or entering text queries  

## Installation:  

### Prerequisites:  
Python 3.8+  
PyTorch 1.9+  
FAISS  
Flask  
